{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1c2f0bde",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72126b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b383c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "update=[]\n",
    "veiws=[]\n",
    "\n",
    "\n",
    "#scrapping  rank from webpage\n",
    "rank_tags=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in rank_tags:\n",
    "    ranka=i.text\n",
    "    rank.append(ranka)\n",
    "#scrapping name\n",
    "name_tags=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in name_tags:\n",
    "    namea=i.text\n",
    "    name.append(namea)\n",
    "#scrapping artist\n",
    "artist_tags=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in artist_tags:\n",
    "    artista=i.text\n",
    "    artist.append(artista)\n",
    "#scrapping update\n",
    "update_tags=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "for i in update_tags:\n",
    "    updatea=i.text\n",
    "    update.append(updatea)\n",
    "#scrapping veiws\n",
    "veiws_tags=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in veiws_tags:\n",
    "    veiwsa=i.text\n",
    "    veiws.append(veiwsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1=rank[0:30]\n",
    "name1=name[0:30]\n",
    "artist1=artist[0:30]\n",
    "update1=update[0:30]\n",
    "veiws1=veiws[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3624c6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ARTIST</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "      <th>VEIWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[49]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                             NAME  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                     \"Axel F\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.                             \"Lakdi Ki Kathi\"[49]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[50]   \n",
       "\n",
       "                                           ARTIST        UPLOAD DATE  VEIWS  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.37  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.09  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.63  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.03  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.92  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.79  \n",
       "6                                       ChuChu TV      March 6, 2014   5.17  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   4.95  \n",
       "8                                     Mark Ronson  November 19, 2014   4.84  \n",
       "9                                     Miroshka TV  February 27, 2018   4.83  \n",
       "10                                            Psy      July 15, 2012   4.70  \n",
       "11                                     Get Movies   January 31, 2012   4.53  \n",
       "12                                      El Chombo      April 5, 2018   4.24  \n",
       "13                                       Maroon 5   January 14, 2015   3.82  \n",
       "14                                     Crazy Frog      June 16, 2009   3.76  \n",
       "15                                     Katy Perry  September 5, 2013   3.73  \n",
       "16                                    OneRepublic       May 31, 2013   3.73  \n",
       "17                                  Justin Bieber   October 22, 2015   3.63  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.55  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.51  \n",
       "20                                        Shakira       June 4, 2010   3.48  \n",
       "21                                     Katy Perry  February 20, 2014   3.45  \n",
       "22                                    Alan Walker   December 3, 2015   3.41  \n",
       "23                                      Passenger      July 25, 2012   3.38  \n",
       "24                                       Maroon 5       May 31, 2018   3.37  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.37  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.34  \n",
       "27                                    Major Lazer     March 22, 2015   3.33  \n",
       "28                                   Jingle Toons      June 14, 2018   3.32  \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.31  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"RANK\":rank1,\"NAME\":name1,\"ARTIST\":artist1,\"UPLOAD DATE\":update1,\"VEIWS\":veiws1})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4b36cf5",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a243867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d433738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on international\n",
    "inter=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "inter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c182b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data\n",
    "title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "\n",
    "\n",
    "#scrapping  title from webpage\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title_tags:\n",
    "    titlea=i.text\n",
    "    title.append(titlea)\n",
    "#scrapping series\n",
    "series_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series_tags:\n",
    "    seriesa=i.text\n",
    "    series.append(seriesa)\n",
    "#scrapping place\n",
    "place_tags=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in place_tags:\n",
    "    placea=i.text\n",
    "    place.append(placea)\n",
    "#scrapping date\n",
    "date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tags:\n",
    "    datea=i.text\n",
    "    date.append(datea)\n",
    "#scrapping time\n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags:\n",
    "    timea=i.text\n",
    "    time.append(timea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ea2097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>SERIES</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match title                         SERIES          PLACE         DATE  \\\n",
       "0     1st ODI -  AUSTRALIA TOUR OF INDIA 2023         Mumbai  17 MAR 2023   \n",
       "1     2nd ODI -  AUSTRALIA TOUR OF INDIA 2023  Visakhapatnam  19 MAR 2023   \n",
       "2     3rd ODI -  AUSTRALIA TOUR OF INDIA 2023        Chennai  22 MAR 2023   \n",
       "\n",
       "          TIME  \n",
       "0  1:30 PM IST  \n",
       "1  1:30 PM IST  \n",
       "2  1:30 PM IST  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\" Match title \":title,\"SERIES\":series,\"PLACE\":place,\"DATE\":date,\"TIME\":time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "212a3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3 3 3\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(series),len(place),len(date),len(time))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cea7177",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3444db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "965bbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on economy\n",
    "eco=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "eco.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea0d292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on india\n",
    "ind=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5413d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on gdp state wise india\n",
    "gdp=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e45e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data\n",
    "rank=[]\n",
    "state=[]\n",
    "gdp1=[]\n",
    "gdp2=[]\n",
    "share=[]\n",
    "gdp3=[]\n",
    "\n",
    "\n",
    "#scrapping rank from webpage\n",
    "rank_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "for i in rank_tags:\n",
    "    ranka=i.text\n",
    "    rank.append(ranka)\n",
    "#scrapping state\n",
    "state_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "for i in state_tags:\n",
    "    statea=i.text\n",
    "    state.append(statea)\n",
    "#scrapping place\n",
    "gdp1_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "for i in gdp1_tags:\n",
    "    gdp1a=i.text\n",
    "    gdp1.append(gdp1a)\n",
    "#scrapping date\n",
    "gdp2_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "for i in gdp2_tags:\n",
    "    gdp2a=i.text\n",
    "    gdp2.append(gdp2a)\n",
    "#scrapping time\n",
    "share_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "for i in share_tags:\n",
    "    sharea=i.text\n",
    "    share.append(sharea)\n",
    "#scrapping date\n",
    "gdp3_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "for i in gdp3_tags:\n",
    "    gdp3a=i.text\n",
    "    gdp3.append(gdp3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ffb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      1,845,853   \n",
       "2     3              Uttar Pradesh                      1,687,818   \n",
       "3     4                    Gujarat                              -   \n",
       "4     5                  Karnataka                      1,631,977   \n",
       "..  ...                        ...                            ...   \n",
       "61   29                     Sikkim                         28,391   \n",
       "62   30                   Nagaland                              -   \n",
       "63   31          Arunachal Pradesh                              -   \n",
       "64   32                    Mizoram                         24,424   \n",
       "65   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                       2,632,792       13.94%        399.921  \n",
       "1                       1,630,208        8.63%        247.629  \n",
       "2                       1,584,764        8.39%        240.726  \n",
       "3                       1,502,899        7.96%        228.290  \n",
       "4                       1,493,127        7.91%        226.806  \n",
       "..                            ...          ...            ...  \n",
       "61                         25,141        0.15%         17,060  \n",
       "62                         24,534        0.15%              -  \n",
       "63                         22,488        0.13%              -  \n",
       "64                         20,947        0.13%         17,797  \n",
       "65                              -            -              -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Rank\":rank,\"State\":state,\"GSDP(18-19)- at current prices\":gdp1,\"GSDP(19-20)- at current prices\":gdp2,\"Share(18-19)\":share,\"GDP($ billion)\":gdp3})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5711439",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21f938e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a981b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on opensource\n",
    "os=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "os.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e623a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on trending\n",
    "tr=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\")\n",
    "tr.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516b1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data\n",
    "title=[]\n",
    "desp=[]\n",
    "contc=[]\n",
    "lang=[]\n",
    "\n",
    "\n",
    "#scrapping totle from webpage\n",
    "title_tags=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in title_tags:\n",
    "    titlea=i.text\n",
    "    title.append(titlea)\n",
    "#scrapping desc\n",
    "desp_tags=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desp_tags:\n",
    "    despa=i.text\n",
    "    desp.append(despa)\n",
    "#scrapping cont\n",
    "contc_tags=driver.find_elements(By.XPATH,'//a[@class=\"Link--muted d-inline-block mr-3\"][1]')\n",
    "for i in contc_tags:\n",
    "    contca=i.text\n",
    "    contc.append(contca)\n",
    "#scrapping language\n",
    "lang_tags=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lang_tags:\n",
    "    langa=i.text\n",
    "    lang.append(langa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20fa2079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatsu-lab / stanford_alpaca</td>\n",
       "      <td>Code and documentation to train Stanford's Alp...</td>\n",
       "      <td>6,045</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ggerganov / llama.cpp</td>\n",
       "      <td>Port of Facebook's LLaMA model in C/C++</td>\n",
       "      <td>7,260</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>togethercomputer / OpenChatKit</td>\n",
       "      <td>Use ChatGPT to summarize the arXiv papers.</td>\n",
       "      <td>4,435</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kaixindelele / ChatPaper</td>\n",
       "      <td>SQL Translator is a tool for converting natura...</td>\n",
       "      <td>1,722</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whoiskatrin / sql-translator</td>\n",
       "      <td>An open-source ChatGPT app with a voice</td>\n",
       "      <td>1,058</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cogentapps / chat-with-gpt</td>\n",
       "      <td>A high-performance, zero-overhead, extensible ...</td>\n",
       "      <td>468</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>exaloop / codon</td>\n",
       "      <td>A powerful and modular stable diffusion GUI wi...</td>\n",
       "      <td>7,376</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comfyanonymous / ComfyUI</td>\n",
       "      <td>Everything required to run your own Base node</td>\n",
       "      <td>1,140</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base-org / node</td>\n",
       "      <td>Web apps in pure Python</td>\n",
       "      <td>15,730</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pynecone-io / pynecone</td>\n",
       "      <td>Create your own ChatGPT App in seconds.</td>\n",
       "      <td>6,799</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>futantan / OpenGpt</td>\n",
       "      <td>Examples and guides for using the OpenAI API</td>\n",
       "      <td>1,891</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>openai / openai-cookbook</td>\n",
       "      <td>A simple and open-source proxy API that allows...</td>\n",
       "      <td>18,234</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ayaka14732 / ChatGPTAPIFree</td>\n",
       "      <td>[CVPR'23] Universal Instance Perception as Obj...</td>\n",
       "      <td>704</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MasterBin-IIAU / UNINEXT</td>\n",
       "      <td>The simplest way to run LLaMA on your local ma...</td>\n",
       "      <td>193</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cocktailpeanut / dalai</td>\n",
       "      <td>Code and models for the paper \"One Transformer...</td>\n",
       "      <td>1,701</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thu-ml / unidiffuser</td>\n",
       "      <td>这儿收集了一些免费好用的ChatGPT镜像站 当前：55个站点</td>\n",
       "      <td>513</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xx025 / carrot</td>\n",
       "      <td>Display and control your Android device</td>\n",
       "      <td>968</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Genymobile / scrcpy</td>\n",
       "      <td>Upscayl - Free and Open Source AI Image Upscal...</td>\n",
       "      <td>78,819</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>upscayl / upscayl</td>\n",
       "      <td>拼多多事件的脱壳后的部分代码</td>\n",
       "      <td>10,157</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>poorjobless / pinduoduo_backdoor_code</td>\n",
       "      <td>A CLI tool to get help with CLI tools</td>\n",
       "      <td>124</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>orhun / halp</td>\n",
       "      <td>Reverse engineered API of Microsoft's Bing Chat</td>\n",
       "      <td>343</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acheong08 / EdgeGPT</td>\n",
       "      <td>High-performance GPGPU inference of OpenAI's W...</td>\n",
       "      <td>2,842</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Const-me / Whisper</td>\n",
       "      <td>Inference code for LLaMA models</td>\n",
       "      <td>675</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Repository title  \\\n",
       "0             tatsu-lab / stanford_alpaca   \n",
       "1                   ggerganov / llama.cpp   \n",
       "2          togethercomputer / OpenChatKit   \n",
       "3                kaixindelele / ChatPaper   \n",
       "4            whoiskatrin / sql-translator   \n",
       "5              cogentapps / chat-with-gpt   \n",
       "6                         exaloop / codon   \n",
       "7                comfyanonymous / ComfyUI   \n",
       "8                         base-org / node   \n",
       "9                  pynecone-io / pynecone   \n",
       "10                     futantan / OpenGpt   \n",
       "11               openai / openai-cookbook   \n",
       "12            ayaka14732 / ChatGPTAPIFree   \n",
       "13               MasterBin-IIAU / UNINEXT   \n",
       "14                 cocktailpeanut / dalai   \n",
       "15                   thu-ml / unidiffuser   \n",
       "16                         xx025 / carrot   \n",
       "17                    Genymobile / scrcpy   \n",
       "18                      upscayl / upscayl   \n",
       "19  poorjobless / pinduoduo_backdoor_code   \n",
       "20                           orhun / halp   \n",
       "21                    acheong08 / EdgeGPT   \n",
       "22                     Const-me / Whisper   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Code and documentation to train Stanford's Alp...              6,045   \n",
       "1             Port of Facebook's LLaMA model in C/C++              7,260   \n",
       "2          Use ChatGPT to summarize the arXiv papers.              4,435   \n",
       "3   SQL Translator is a tool for converting natura...              1,722   \n",
       "4             An open-source ChatGPT app with a voice              1,058   \n",
       "5   A high-performance, zero-overhead, extensible ...                468   \n",
       "6   A powerful and modular stable diffusion GUI wi...              7,376   \n",
       "7       Everything required to run your own Base node              1,140   \n",
       "8                             Web apps in pure Python             15,730   \n",
       "9             Create your own ChatGPT App in seconds.              6,799   \n",
       "10       Examples and guides for using the OpenAI API              1,891   \n",
       "11  A simple and open-source proxy API that allows...             18,234   \n",
       "12  [CVPR'23] Universal Instance Perception as Obj...                704   \n",
       "13  The simplest way to run LLaMA on your local ma...                193   \n",
       "14  Code and models for the paper \"One Transformer...              1,701   \n",
       "15                    这儿收集了一些免费好用的ChatGPT镜像站 当前：55个站点                513   \n",
       "16            Display and control your Android device                968   \n",
       "17  Upscayl - Free and Open Source AI Image Upscal...             78,819   \n",
       "18                                     拼多多事件的脱壳后的部分代码             10,157   \n",
       "19              A CLI tool to get help with CLI tools                124   \n",
       "20    Reverse engineered API of Microsoft's Bing Chat                343   \n",
       "21  High-performance GPGPU inference of OpenAI's W...              2,842   \n",
       "22                    Inference code for LLaMA models                675   \n",
       "\n",
       "       Language used  \n",
       "0             Python  \n",
       "1                  C  \n",
       "2             Python  \n",
       "3             Python  \n",
       "4         TypeScript  \n",
       "5         TypeScript  \n",
       "6                C++  \n",
       "7             Python  \n",
       "8              Shell  \n",
       "9             Python  \n",
       "10        TypeScript  \n",
       "11  Jupyter Notebook  \n",
       "12        JavaScript  \n",
       "13            Python  \n",
       "14        JavaScript  \n",
       "15            Python  \n",
       "16                 C  \n",
       "17        TypeScript  \n",
       "18                 C  \n",
       "19              Rust  \n",
       "20            Python  \n",
       "21               C++  \n",
       "22            Python  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\" Repository title\":title1,\"Repository description\":desp,\"Contributors count\":contc1,\"Language used\":lang})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03f90903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 23 23 23\n"
     ]
    }
   ],
   "source": [
    "print(len(title1),len(desp),len(contc1),len(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6832db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title1=title[0:23]\n",
    "contc1=contc[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f750680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2aa1f9a",
   "metadata": {},
   "source": [
    "5.Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "096adb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc5d3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on charts\n",
    "ch=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "ch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b85b4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button/span\")\n",
    "ch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e551aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking hot 100\n",
    "h100=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a\")\n",
    "h100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dab3234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname=[]\n",
    "aname=[]\n",
    "lwr=[]\n",
    "pr=[]\n",
    "wob=[]\n",
    "\n",
    "#scrapping song name from webpage\n",
    "sname_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for i in sname_tags:\n",
    "    try:\n",
    "        snamea=i.text\n",
    "        sname.append(snamea)\n",
    "    except NoSuchElementException:\n",
    "        sname.append(\"-\")\n",
    "\n",
    "#scrapping artistname\n",
    "aname_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "for i in aname_tags:\n",
    "    try:\n",
    "        anamea=i.text\n",
    "        aname.append(anamea)\n",
    "    except NoSuchElementException:\n",
    "        aname.append(\"-\")\n",
    "\n",
    "#scrapping last week rank\n",
    "lwr_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]')\n",
    "for i in lwr_tags:\n",
    "    try:\n",
    "        lwra=i.text\n",
    "        lwr.append(lwra)\n",
    "    except NoSuchElementException:\n",
    "        contc.append(\"-\")\n",
    "\n",
    "#scrapping peak rank\n",
    "pr_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]')\n",
    "for i in pr_tags:\n",
    "    try:\n",
    "        pra=i.text\n",
    "        pr.append(pra)\n",
    "    except NoSuchElementException:\n",
    "        pr.append(\"-\")\n",
    "#scrapping weeks on board\n",
    "wob_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]')\n",
    "for i in wob_tags:\n",
    "    try:\n",
    "        woba=i.text\n",
    "        wob.append(woba)\n",
    "    except NoSuchElementException:\n",
    "        wob.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8239302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(wob),len(pr),len(lwr),len(sname),len(aname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5394c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SONG NAME</th>\n",
       "      <th>ARTIST NAME</th>\n",
       "      <th>LAST WEEK RANK</th>\n",
       "      <th>PEAK RANK</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die For You</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy's A Liar, Pt. 2</td>\n",
       "      <td>PinkPantheress &amp; Ice Spice</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nonsense</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AMG</td>\n",
       "      <td>Gabito Ballesteros, Peso Pluma &amp; Natanael Cano</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lift Me Up</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>You Didn't</td>\n",
       "      <td>Brett Young</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10:35</td>\n",
       "      <td>Tiesto Featuring Tate McRae</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SONG NAME                                     ARTIST NAME  \\\n",
       "0            Last Night                                   Morgan Wallen   \n",
       "1               Flowers                                     Miley Cyrus   \n",
       "2             Kill Bill                                             SZA   \n",
       "3           Die For You                      The Weeknd & Ariana Grande   \n",
       "4   Boy's A Liar, Pt. 2                      PinkPantheress & Ice Spice   \n",
       "..                  ...                                             ...   \n",
       "95             Nonsense                               Sabrina Carpenter   \n",
       "96                  AMG  Gabito Ballesteros, Peso Pluma & Natanael Cano   \n",
       "97           Lift Me Up                                         Rihanna   \n",
       "98           You Didn't                                     Brett Young   \n",
       "99                10:35                     Tiesto Featuring Tate McRae   \n",
       "\n",
       "   LAST WEEK RANK PEAK RANK Weeks on board  \n",
       "0               5         1              6  \n",
       "1               2         1              8  \n",
       "2               3         2             13  \n",
       "3               1         1             32  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             75        56              8  \n",
       "96             80        66              7  \n",
       "97             65         2             19  \n",
       "98             78        63              9  \n",
       "99             81        69              7  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"SONG NAME\":sname,\"ARTIST NAME\":aname,\"LAST WEEK RANK\":lwr,\"PEAK RANK\":pr,\"Weeks on board\":wob})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "031f61d1",
   "metadata": {},
   "source": [
    "6.Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbf5ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "033d8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "bname=[]\n",
    "aname=[]\n",
    "vs=[]\n",
    "pr=[]\n",
    "genre=[]\n",
    "\n",
    "#scrapping song name from webpage\n",
    "bname_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in bname_tags:\n",
    "    try:\n",
    "        bnamea=i.text\n",
    "        bname.append(bnamea)\n",
    "    except NoSuchElementException:\n",
    "        bname.append(\"-\")\n",
    "\n",
    "#scrapping artistname\n",
    "aname_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in aname_tags:\n",
    "    try:\n",
    "        anamea=i.text\n",
    "        aname.append(anamea)\n",
    "    except NoSuchElementException:\n",
    "        aname.append(\"-\")\n",
    "\n",
    "#scrapping last week rank\n",
    "vs_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in vs_tags:\n",
    "    try:\n",
    "        vsa=i.text\n",
    "        vs.append(vsa)\n",
    "    except NoSuchElementException:\n",
    "        vs.append(\"-\")\n",
    "\n",
    "#scrapping peak rank\n",
    "pr_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in pr_tags:\n",
    "    try:\n",
    "        pra=i.text\n",
    "        pr.append(pra)\n",
    "    except NoSuchElementException:\n",
    "        pr.append(\"-\")\n",
    "#scrapping weeks on board\n",
    "genre_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in genre_tags:\n",
    "    try:\n",
    "        genrea=i.text\n",
    "        genre.append(genrea)\n",
    "    except NoSuchElementException:\n",
    "        genre.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77268a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK NAME</th>\n",
       "      <th>AUTHOR NAME</th>\n",
       "      <th>VOLUME SOLD</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            BOOK NAME       AUTHOR NAME  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   VOLUME SOLD        Publisher                        GENRE  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"BOOK NAME\":bname,\"AUTHOR NAME\":aname,\"VOLUME SOLD\":vs,\"Publisher\":pr,\"GENRE\":genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea860a24",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "701fd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0bf4da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "runtime=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "#scrapping name from webpage\n",
    "name_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/a')\n",
    "for i in name_tags:\n",
    "    try:\n",
    "        namea=i.text\n",
    "        name.append(namea)\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"-\")\n",
    "\n",
    "#scrapping year\n",
    "year_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "for i in year_tags:\n",
    "    try:\n",
    "        yeara=i.text\n",
    "        year.append(yeara)\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"-\")\n",
    "\n",
    "#scrapping genre\n",
    "genre_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "for i in genre_tags:\n",
    "    try:\n",
    "        genrea=i.text\n",
    "        genre.append(genrea)\n",
    "    except NoSuchElementException:\n",
    "        genre.append(\"-\")\n",
    "\n",
    "#scrapping runtime\n",
    "run_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[3]')\n",
    "for i in run_tags:\n",
    "    try:\n",
    "        runa=i.text\n",
    "        runtime.append(runa)\n",
    "    except NoSuchElementException:\n",
    "        runtime.append(\"-\")\n",
    "#scrapping ratings\n",
    "rat_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div/div[1]')\n",
    "for i in rat_tags:\n",
    "    try:\n",
    "        rata=i.text\n",
    "        ratings.append(rata)\n",
    "    except NoSuchElementException:\n",
    "        ratings.append(\"-\")\n",
    "\n",
    "#scrapping votes\n",
    "vt_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]')\n",
    "for i in vt_tags:\n",
    "    try:\n",
    "        vta=i.text\n",
    "        votes.append(vta)\n",
    "    except NoSuchElementException:\n",
    "        votes.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "591bfdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>YEAR SPAN</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>RUN TIME</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Votes: 2,137,670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Votes: 1,222,654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Votes: 1,014,796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Votes: 298,929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Votes: 257,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Votes: 51,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Votes: 63,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Votes: 204,858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Votes: 42,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Votes: 253,481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              NAME    YEAR SPAN                     GENRE  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   RUN TIME RATINGS             VOTES  \n",
       "0    57 min     9.2  Votes: 2,137,670  \n",
       "1    51 min     8.7  Votes: 1,222,654  \n",
       "2    44 min     8.1  Votes: 1,014,796  \n",
       "3    60 min     7.5    Votes: 298,929  \n",
       "4    43 min     7.6    Votes: 257,799  \n",
       "..      ...     ...               ...  \n",
       "95   42 min     7.4     Votes: 51,002  \n",
       "96   50 min     7.8     Votes: 63,015  \n",
       "97   42 min     8.1    Votes: 204,858  \n",
       "98   45 min     7.1     Votes: 42,419  \n",
       "99  572 min     8.6    Votes: 253,481  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"NAME\":name,\"YEAR SPAN\":year,\"GENRE\":genre,\"RUN TIME\":runtime,\"RATINGS\":ratings,\"VOTES\":votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "533ed9c4",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a52e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1683216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on datsets\n",
    "cl=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "cl.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "176abc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "typ=[]\n",
    "task=[]\n",
    "aty=[]\n",
    "noi=[]\n",
    "noa=[]\n",
    "year=[]\n",
    "\n",
    "#scrapping name from webpage\n",
    "name_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[1]')\n",
    "for i in name_tags:\n",
    "    try:\n",
    "        namea=i.text\n",
    "        name.append(namea)\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"-\")\n",
    "\n",
    "#scrapping data type\n",
    "typ_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[2]')\n",
    "for i in typ_tags:\n",
    "    try:\n",
    "        typa=i.text\n",
    "        typ.append(typa)\n",
    "    except NoSuchElementException:\n",
    "        typ.append(\"-\")\n",
    "\n",
    "#scrapping task\n",
    "task_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[3]')\n",
    "for i in task_tags:\n",
    "    try:\n",
    "        taska=i.text\n",
    "        task.append(taska)\n",
    "    except NoSuchElementException:\n",
    "        task.append(\"-\")\n",
    "\n",
    "#scrapping attribute type\n",
    "aty_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[4]')\n",
    "for i in aty_tags:\n",
    "    try:\n",
    "        atya=i.text\n",
    "        aty.append(atya)\n",
    "    except NoSuchElementException:\n",
    "        aty.append(\"-\")\n",
    "#scrapping no. of instance\n",
    "noi_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[5]')\n",
    "for i in noi_tags:\n",
    "    try:\n",
    "        noia=i.text\n",
    "        noi.append(noia)\n",
    "    except NoSuchElementException:\n",
    "        noi.append(\"-\")\n",
    "\n",
    "#scrapping no. of attribute\n",
    "noa_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[6]')\n",
    "for i in noa_tags:\n",
    "    try:\n",
    "        noaa=i.text\n",
    "        noa.append(noaa)\n",
    "    except NoSuchElementException:\n",
    "        noa.append(\"-\")\n",
    "#scrapping year\n",
    "year_tags=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[7]')\n",
    "for i in year_tags:\n",
    "    try:\n",
    "        yeara=i.text\n",
    "        year.append(yeara)\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f028434",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1=name[1:623]\n",
    "typ1=typ[1:623]\n",
    "aty1=aty[1:623]\n",
    "noi1=noi[1:623]\n",
    "noa1=noa[1:623]\n",
    "year1=year[1:623]\n",
    "task1=task[1:623]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a421b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET NAME</th>\n",
       "      <th>DATA TYPE</th>\n",
       "      <th>TASK</th>\n",
       "      <th>ATTRIBUTE TYPE</th>\n",
       "      <th>NO. OF INSTANCE</th>\n",
       "      <th>NO. OF ATTRIBUTE</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          DATASET NAME  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                      DATA TYPE                  TASK  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  ATTRIBUTE TYPE NO. OF INSTANCE NO. OF ATTRIBUTE   YEAR  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"DATASET NAME\":name1,\"DATA TYPE\":typ1,\"TASK\":task1,\"ATTRIBUTE TYPE\":aty1,\"NO. OF INSTANCE\":noi1,\"NO. OF ATTRIBUTE\":noa1,\"YEAR\":year1})\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23e3cd31",
   "metadata": {},
   "source": [
    "9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company\n",
    "D)Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d435791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening  page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab3ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location\n",
    "designation=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input' )\n",
    "designation.send_keys(\"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b3a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6806df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]')\n",
    "for i in url:\n",
    "    rec_url.append(i.get_attribute('href'))\n",
    "    next_button=driver.find_elements(By.XPATH,'/html/body/div[3]/div/div[2]/div/div[3]/button')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47fa545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/recruiters/aakashharit-1986742?xid=167895877180941400&xp=1',\n",
       " 'https://www.naukri.com/data-science-network-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/shravankumargaddam-353487?xid=167895877180941400&xp=2',\n",
       " 'https://www.naukri.com/shore-infotech-india-pvt-dot-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/marsiantech?xid=167895877180941400&xp=3',\n",
       " 'https://www.naukri.com/marsian-technologies-llp-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/anikagrawal-3647208?xid=167895877180941400&xp=4',\n",
       " 'https://www.naukri.com/enerlytics-software-solutions-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/LXP-DATASCIENCE?xid=167895877180941400&xp=5',\n",
       " 'https://www.naukri.com/libraryxproject-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/abhishekyadav-3450244?xid=167895877180941400&xp=6',\n",
       " 'https://www.naukri.com/apidel-technologies-division-of-transpower-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/menakav-3213816?xid=167895877180941400&xp=7',\n",
       " 'https://www.naukri.com/ifmr-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/techvantage?xid=167895877180941400&xp=8',\n",
       " 'https://www.naukri.com/techvantage-systems-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/asiflucknowi-4331110?xid=167895877180941400&xp=9',\n",
       " 'https://www.naukri.com/weupskill--live-wire-india-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/instafinancials-humanresource?xid=167895877180941400&xp=10',\n",
       " 'https://www.naukri.com/cbl-data-science-private-limited-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/kalpana-2078894?xid=167895877180941400&xp=11',\n",
       " 'https://www.naukri.com/innominds-software-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/mubarak-2905498?xid=167895877180941400&xp=12',\n",
       " 'https://www.naukri.com/moneytap-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/quantmagnum?xid=167895877180941400&xp=13',\n",
       " 'https://www.naukri.com/quantmagnum-technologies-pvt-dot-ltd-dot-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/maheshbabuchanna-1803238?xid=167895877180941400&xp=14',\n",
       " 'https://www.naukri.com/socialprachar-dot-com-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/priyankaakiri-5010064?xid=167895877180941400&xp=15',\n",
       " 'https://www.naukri.com/infinitive-software-solutions-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/kapildevang-3169734?xid=167895877180941400&xp=16',\n",
       " 'https://www.naukri.com/bisp-solutions-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/vaishnavikudalkar-5205628?xid=167895877180941400&xp=17',\n",
       " 'https://www.naukri.com/codeachive-learning-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/sakshichhikara?xid=167895877180941400&xp=18',\n",
       " 'https://www.naukri.com/biz-infotecno-private-limited-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/ruchidhote?xid=167895877180941400&xp=19',\n",
       " 'https://www.naukri.com/bristlecone-india-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/manishayadav-4463916?xid=167895877180941400&xp=20',\n",
       " 'https://www.naukri.com/easi-tax-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/riyarajesh-4375878?xid=167895877180941400&xp=21',\n",
       " 'https://www.naukri.com/novelworx-digital-solutions-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rashmibhattacharjee-3921774?xid=167895877180941400&xp=22',\n",
       " 'https://www.naukri.com/axestrack-software-solutions-private-limited-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/faizankareem-3685102?xid=167895877180941400&xp=23',\n",
       " 'https://www.naukri.com/firsttech-consaltants-pvt-dot-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rithikadadwal-3517898?xid=167895877180941400&xp=24',\n",
       " 'https://www.naukri.com/affine-analytics-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/ankitshah-21129?xid=167895877180941400&xp=25',\n",
       " 'https://www.naukri.com/compumatrice-multimedia-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/shaunrao-3020604?xid=167895877180941400&xp=26',\n",
       " 'https://www.naukri.com/exela-technologies-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/deeparchisharma?xid=167895877180941400&xp=27',\n",
       " 'https://www.naukri.com/zigram-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/azaharshaikh-companyrecruiter?xid=167895877180941400&xp=28',\n",
       " 'https://www.naukri.com/neal-analytics-services-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/manas-3159036?xid=167895877180941400&xp=29',\n",
       " 'https://www.naukri.com/autumn-leaf-consulting-services-private-limited-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/kumar-3378892?xid=167895877180941400&xp=30',\n",
       " 'https://www.naukri.com/trainin-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/sunilvedula-3392046?xid=167895877180941400&xp=31',\n",
       " 'https://www.naukri.com/nanoprecise-sci-corp-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rajatkumar-3295096?xid=167895877180941400&xp=32',\n",
       " 'https://www.naukri.com/r-dot-s-consultancy-amp-services-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/dhruvdevdubey?xid=167895877180941400&xp=33',\n",
       " 'https://www.naukri.com/netaps-foundation-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/avnishmishra-5310575?xid=167895877180941400&xp=34',\n",
       " 'https://www.naukri.com/rms-risk-management-solutions-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/jayanthn-3081850?xid=167895877180941400&xp=35',\n",
       " 'https://www.naukri.com/dollarbird-information-services-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/nikithapalaparthi-5172698?xid=167895877180941400&xp=36',\n",
       " 'https://www.naukri.com/nikitha-palaparthi-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/priyakhare-4894796?xid=167895877180941400&xp=37',\n",
       " 'https://www.naukri.com/independent-consultant-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/amitsharma-4238940?xid=167895877180941400&xp=38',\n",
       " 'https://www.naukri.com/asco-consulting-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/deepali002g?xid=167895877180941400&xp=39',\n",
       " 'https://www.naukri.com/ny-inst-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/shashikantchaudhary-4164854?xid=167895877180941400&xp=40',\n",
       " 'https://www.naukri.com/3d-india-staffing-research-amp-consulting-co-dot-india-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/brad-4068508?xid=167895877180941400&xp=41',\n",
       " 'https://www.naukri.com/o-dot-c-dot-tanner-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rutujapawar?xid=167895877180941400&xp=42',\n",
       " 'https://www.naukri.com/demand-matrix-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/madhusudhansridhar-2705338?xid=167895877180941400&xp=43',\n",
       " 'https://www.naukri.com/madhusudhan-sridhar-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/ankitsinha-3398798?xid=167895877180941400&xp=44',\n",
       " 'https://www.naukri.com/suntech-global-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/gauravchouhan?xid=167895877180941400&xp=45',\n",
       " 'https://www.naukri.com/strategic-consulting-lab-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/impel?xid=167895877180941400&xp=46',\n",
       " 'https://www.naukri.com/impel-labs-pvt-dot-ltd-dot-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/ashwini-3434922?xid=167895877180941400&xp=47',\n",
       " 'https://www.naukri.com/mrp-advisers-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/balajikolli-2870676?xid=167895877180941400&xp=48',\n",
       " 'https://www.naukri.com/saras-solutions-india-pvt-ltd-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rajaninagaraj-3387578?xid=167895877180941400&xp=49',\n",
       " 'https://www.naukri.com/wildjasmine-recruiters?qsp=1',\n",
       " 'https://www.naukri.com/recruiters/rohitkumar-3277680?xid=167895877180941400&xp=50',\n",
       " 'https://www.naukri.com/lnt-private-limited-recruiters?qsp=1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15ce22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=[]\n",
    "designation_list=[]\n",
    "company_list=[]\n",
    "skills_list=[]\n",
    "location_list=[]\n",
    "\n",
    "\n",
    "for url in rec_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'//h1[@class=\"fl ellipsis wLimit hd\"]')\n",
    "        name_list.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        name_list.append('-')\n",
    "    try:\n",
    "        designation=driver.find_element(By.XPATH,'//div[@class=\"ellipsis\"]')\n",
    "        designation_list.append(designation.text)\n",
    "    except NoSuchElementException:\n",
    "        designation_list.append('-')\n",
    "    try:\n",
    "        company=driver.find_element(By.XPATH,'//div[@class=\"oh\"][1]/a')\n",
    "        company_list.append(company.text)\n",
    "    except NoSuchElementException:\n",
    "        company_list.append('-')\n",
    "    try:\n",
    "        skills=driver.find_element(By.XPATH,'//div[@class=\"fl lPortn\"]/p')\n",
    "        skills_list.append(skills.text)\n",
    "    except NoSuchElementException:\n",
    "        skills_list.append('-')\n",
    "    try:\n",
    "        location=driver.find_element(By.XPATH,'//div[@class=\"oh\"][2]/a')\n",
    "        location_list.append(location.text)\n",
    "    except NoSuchElementException:\n",
    "        location_list.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402ef4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>sKILLS THEY HIRE FOR</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NAME        DESIGNATION  \\\n",
       "0               Aakash Harit         HR Manager   \n",
       "1                          -                  -   \n",
       "2       shravan Kumar Gaddam  Company Recruiter   \n",
       "3                          -                  -   \n",
       "4   MARSIAN Technologies LLP         Company HR   \n",
       "..                       ...                ...   \n",
       "95                         -                  -   \n",
       "96            Rajani Nagaraj         HR Manager   \n",
       "97                         -                  -   \n",
       "98               ROHIT Kumar          Architect   \n",
       "99                         -                  -   \n",
       "\n",
       "                          COMPANY  \\\n",
       "0            Data Science Network   \n",
       "1                               -   \n",
       "2   Shore Infotech India Pvt. Ltd   \n",
       "3                               -   \n",
       "4        MARSIAN Technologies LLP   \n",
       "..                            ...   \n",
       "95                              -   \n",
       "96                    WildJasmine   \n",
       "97                              -   \n",
       "98            LNT Private Limited   \n",
       "99                              -   \n",
       "\n",
       "                                 sKILLS THEY HIRE FOR  \\\n",
       "0   Classic ASP Developer , Internet Marketing Pro...   \n",
       "1                                                   -   \n",
       "2   .Net , Java , Data Science , Linux Administrat...   \n",
       "3                                                   -   \n",
       "4                             Mid Level, Junior Level   \n",
       "..                                                ...   \n",
       "95                                                  -   \n",
       "96  java , hadoop , r , Machine Learning , spark ,...   \n",
       "97                                                  -   \n",
       "98                              Mid Level, High Level   \n",
       "99                                                  -   \n",
       "\n",
       "                    LOCATION  \n",
       "0                      Delhi  \n",
       "1                          -  \n",
       "2   Hyderabad / Secunderabad  \n",
       "3                          -  \n",
       "4                       Pune  \n",
       "..                       ...  \n",
       "95                         -  \n",
       "96     Bengaluru / Bangalore  \n",
       "97                         -  \n",
       "98                    Mumbai  \n",
       "99                         -  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"NAME\":name_list,\"DESIGNATION\":designation_list,\"COMPANY\":company_list,\"sKILLS THEY HIRE FOR\":skills_list,\"LOCATION\":location_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7cf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d4011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbb1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e75ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ceb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d12460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a727f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a9f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
